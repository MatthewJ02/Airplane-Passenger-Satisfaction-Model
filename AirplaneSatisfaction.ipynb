{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385c24fa-e14a-4625-a8ce-be55d74e0b86",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron for Predicting Airplane Passenger Satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f16fd-f708-49cc-88e9-dea3a537a254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 1: Imports\n",
    "This cell imports the necessary libraries for retrieving the data from Kaggle, creating the model, and testing/visualizing its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1409a-1e3f-4cc6-80bc-bd30e20330ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import kagglehub\n",
    "import pandas\n",
    "import torch\n",
    "import sagemaker\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7f82f-e2d3-472e-ac97-c570d6147cd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 2: Setup\n",
    "This cell handles basic setup for creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f6feb-49e1-4a69-b053-c43c2f5f308a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup SageMaker\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'sagemaker/airplane-satisfaction'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480920a1-9ae4-4d6c-9350-927ebeea3243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 3: Retrieve Data\n",
    "This cell retrieves the dataset from kaggle and stores the paths for the training and testing portions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a2495-0a75-4785-95e0-1ac69cfb7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Airplane Satisfaction dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"teejmahal20/airline-passenger-satisfaction\")\n",
    "\n",
    "training_path = f\"{path}/train.csv\"\n",
    "testing_path = f\"{path}/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036c4ae-35e4-4b17-a7d3-c73b31ff9d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 4: Preprocess Data\n",
    "This cell handles the preprocessing of the data. Columns are encoded into numerical representation and unneeded columns are removed. The data is split into inputs and the output, null values are filled in with the median for their column, and the data is scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45868f9c-6064-485f-ade1-04606c6c64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "\n",
    "# First create dataframes\n",
    "training_DF = pandas.read_csv(training_path)\n",
    "testing_DF = pandas.read_csv(testing_path)\n",
    "\n",
    "# Encode columns\n",
    "encode_gender = LabelEncoder()\n",
    "\n",
    "training_DF['Gender Encoded'] = encode_gender.fit_transform(training_DF['Gender'])\n",
    "testing_DF['Gender Encoded'] = encode_gender.transform(testing_DF['Gender'])\n",
    "\n",
    "encode_customer_type = LabelEncoder()\n",
    "\n",
    "training_DF['Customer Type Encoded'] = encode_customer_type.fit_transform(training_DF['Customer Type'])\n",
    "testing_DF['Customer Type Encoded'] = encode_customer_type.transform(testing_DF['Customer Type'])\n",
    "\n",
    "encode_travel_type = LabelEncoder()\n",
    "\n",
    "training_DF['Travel Type Encoded'] = encode_travel_type.fit_transform(training_DF['Type of Travel'])\n",
    "testing_DF['Travel Type Encoded'] = encode_travel_type.transform(testing_DF['Type of Travel'])\n",
    "\n",
    "encode_satisfaction = LabelEncoder()\n",
    "\n",
    "training_DF['Satisfaction Encoded'] = encode_satisfaction.fit_transform(training_DF['satisfaction'])\n",
    "testing_DF['Satisfaction Encoded'] = encode_satisfaction.transform(testing_DF['satisfaction'])\n",
    "\n",
    "training_DF = pandas.get_dummies(training_DF, columns=['Class'], prefix='Class', dtype=int)\n",
    "testing_DF = pandas.get_dummies(testing_DF, columns=['Class'], prefix='Class', dtype=int)\n",
    "\n",
    "# Drop unneeded columns\n",
    "dropColumns = ['Unnamed: 0', 'id', 'Gender', 'Customer Type', 'Type of Travel', 'Inflight wifi service', 'satisfaction']\n",
    "\n",
    "training_DF = training_DF.drop(columns=dropColumns)\n",
    "testing_DF = testing_DF.drop(columns=dropColumns)\n",
    "\n",
    "# Split into X and Y\n",
    "training_DF_X = training_DF.drop(columns=['Satisfaction Encoded'])\n",
    "testing_DF_X = testing_DF.drop(columns=['Satisfaction Encoded'])\n",
    "\n",
    "training_DF_Y = training_DF['Satisfaction Encoded']\n",
    "testing_DF_Y = testing_DF['Satisfaction Encoded']\n",
    "\n",
    "# Fill in null values\n",
    "print(training_DF_X.isnull().sum())\n",
    "print(testing_DF_X.isnull().sum())\n",
    "\n",
    "training_DF_X = training_DF_X.fillna({'Arrival Delay in Minutes': training_DF_X['Arrival Delay in Minutes'].median()})\n",
    "testing_DF_X = testing_DF_X.fillna({'Arrival Delay in Minutes': testing_DF_X['Arrival Delay in Minutes'].median()})\n",
    "\n",
    "print(training_DF_X.isnull().sum())\n",
    "print(testing_DF_X.isnull().sum())\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_training_X = scaler.fit_transform(training_DF_X)\n",
    "scaled_testing_X = scaler.transform(testing_DF_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687f73d-1bfb-4c97-b533-887c4d6e82b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 5: Upload Data\n",
    "This cell uploads the data to S3 for use in training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd285ee-7657-40ef-a652-79d8362bee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload preprocessed data to S3\n",
    "scaled_training_DF_X = pandas.DataFrame(scaled_training_X, columns=training_DF_X.columns)\n",
    "\n",
    "training_final_DF = pandas.concat([training_DF_Y.reset_index(drop=True), scaled_training_DF_X], axis=1)\n",
    "\n",
    "training_final_DF.to_csv('training_final.csv', header=False, index=False)\n",
    "\n",
    "training_final_path = session.upload_data('training_final.csv', key_prefix=prefix + '/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60346b10-92cd-49ff-9580-f7f2bb20c199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 6: Model Dimensions\n",
    "This cell calculates and displays the number of input columns and the number of unique outputs for use in creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7183890-5a67-4601-bb3e-98554dafd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dimensions\n",
    "print(scaled_training_DF_X.shape[1])\n",
    "print(training_DF_Y.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d26576-98a2-4751-acea-c79d808810c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 7: Create Training Script\n",
    "This cell writes the Python file which creates the model including instantiation as well as methods for training and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b393a85-56b2-4c0e-a13b-b4fdb327699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    # Instantiate model\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    # Takes the data through the layers of the model\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Handles the training of the model\n",
    "def train(args):\n",
    "    training_dir = args.data_dir\n",
    "    training_data = pandas.read_csv(os.path.join(training_dir, 'training_final.csv'), header=None)\n",
    "\n",
    "    x_train = torch.tensor(training_data.iloc[:, 1:].values).float()\n",
    "    y_train = torch.tensor(training_data.iloc[:, 0].values).long()\n",
    "\n",
    "    model = MLP(args.input_dim, args.hidden_dim, args.output_dim)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Loops through the layers of the model to train on the dataset\n",
    "    for epoch in range(args.epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{args.epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.model_dir, 'model.pth'))\n",
    "\n",
    "# Loads model\n",
    "def model_fn(model_dir):\n",
    "    print(\"Loading model.\")\n",
    "    model = MLP(input_dim=23, hidden_dim = 100, output_dim=2)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Predicts outputs for the given input using the model\n",
    "def predict_fn(input_data, model):\n",
    "    print(\"Making a prediction.\")\n",
    "    with torch.no_grad():\n",
    "        return model(input_data)\n",
    "\n",
    "# Code block for executing the creation and training of the model\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=100)\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--input_dim', type=int, default=23)\n",
    "    parser.add_argument('--hidden_dim', type=int, default=100)\n",
    "    parser.add_argument('--output_dim', type=int, default=2)\n",
    "\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--data-dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d58b6d-56f7-4464-8672-7f5a65ab89be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 8: Run Training Job\n",
    "This cell begins the training of the model which carries through to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0922f-2961-445f-990d-69ae7b48789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training job\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.large',\n",
    "                    framework_version='1.8.0',\n",
    "                    py_version='py3',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 100,\n",
    "                        'lr': 0.01,\n",
    "                        'input_dim': 23,\n",
    "                        'hidden_dim': 100,\n",
    "                        'output_dim': 2\n",
    "                    })\n",
    "estimator.fit({'training': training_final_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e505cf1-b575-45eb-9f53-2d269b662aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 9: Deploy Model\n",
    "This cell handles the deployment of the model allowing future use for predicting from the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d060b-8e1d-4ad4-b73e-b0e4e9977514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3683dc-f1c3-43a3-8baf-074c5794433a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 10: Predict test data set results\n",
    "This cell classifies the passengers in the dataset according to the model. The print statements show a quick check of the first 15 classifications, comparing the real classifications and those chosen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4b167-ef3c-4752-b0b6-542cf2a3a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict results from test set\n",
    "input_tensor = torch.tensor(scaled_testing_X).float()\n",
    "predictions = predictor.predict(input_tensor)\n",
    "predicted_classes = torch.argmax(torch.tensor(predictions), axis=1)\n",
    "\n",
    "# Quick accuracy check\n",
    "print(f\"True labels (first 15): {testing_DF_Y.values[:15]}\")\n",
    "print(f\"Predicted labels (first 15): {predicted_classes.numpy()[:15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442d0a8-19c3-48a2-90d3-e975675caf81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T03:34:04.591081Z",
     "iopub.status.busy": "2025-08-08T03:34:04.590323Z",
     "iopub.status.idle": "2025-08-08T03:34:05.469092Z",
     "shell.execute_reply": "2025-08-08T03:34:05.468378Z",
     "shell.execute_reply.started": "2025-08-08T03:34:04.590982Z"
    }
   },
   "source": [
    "## Cell 11: Comprehensive Accuracy Test\n",
    "This cell does a more complete test of the model's accuracy, generating a score for the model's overall accuracy as well as displaying the model's precision, recall, f1-score, and support for each unique output. Finally, the cell generates a confusion matrix to visualize the accuracy of the model for each unique output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dea79-a05a-4cbe-94a4-b1e61240e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test exact accuracy\n",
    "accuracy = accuracy_score(testing_DF_Y, predicted_classes)\n",
    "print(f\"Overall Model Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "target_names = ['Dissatisfied', 'Satisfied']\n",
    "print(classification_report(testing_DF_Y, predicted_classes, target_names=target_names))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(testing_DF_Y, predicted_classes)\n",
    "plot.figure(figsize=(8, 6))\n",
    "seaborn.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plot.xlabel('Predicted Label')\n",
    "plot.ylabel('True Label')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680697b-e525-4a14-9473-65b208ce1660",
   "metadata": {},
   "source": [
    "## Cell 12: Delete the Endpoint\n",
    "This cell deletes the endpoint and concludes the deployment of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609d40b-11bb-43ee-8b38-db2fc91a2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "print(\"Deleted endpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
